{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#importing important libraries fixing dataset\nimport gensim\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\nmessages=pd.read_csv('../input/spamcsv/spam.csv',encoding='latin1' )\nmessages=messages[['v1','v2']]\nmessages.columns=['label', 'text']\n\n","metadata":{"execution":{"iopub.status.busy":"2022-10-04T23:31:22.883921Z","iopub.execute_input":"2022-10-04T23:31:22.884416Z","iopub.status.idle":"2022-10-04T23:31:24.435166Z","shell.execute_reply.started":"2022-10-04T23:31:22.884324Z","shell.execute_reply":"2022-10-04T23:31:24.434248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#target variable encoding\nlabels=np.where(messages['label']=='spam',1,0)","metadata":{"execution":{"iopub.status.busy":"2022-10-04T23:32:06.041462Z","iopub.execute_input":"2022-10-04T23:32:06.041878Z","iopub.status.idle":"2022-10-04T23:32:06.050677Z","shell.execute_reply.started":"2022-10-04T23:32:06.041847Z","shell.execute_reply":"2022-10-04T23:32:06.049720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train and test split\nX_train, X_test, y_train, y_test= train_test_split(messages['text'], labels, test_size=0.2)\n","metadata":{"execution":{"iopub.status.busy":"2022-10-04T23:32:36.431675Z","iopub.execute_input":"2022-10-04T23:32:36.432075Z","iopub.status.idle":"2022-10-04T23:32:36.439372Z","shell.execute_reply.started":"2022-10-04T23:32:36.432039Z","shell.execute_reply":"2022-10-04T23:32:36.438302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importing tensorflow and model building libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","metadata":{"execution":{"iopub.status.busy":"2022-10-04T23:33:17.571462Z","iopub.execute_input":"2022-10-04T23:33:17.571853Z","iopub.status.idle":"2022-10-04T23:33:23.788551Z","shell.execute_reply.started":"2022-10-04T23:33:17.571822Z","shell.execute_reply":"2022-10-04T23:33:23.787422Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using Tokenizer\n\nTokenizer: Allows to vectorize a text corpus, by turning each text into either a sequence of integers (each integer being the index of a token in a dictionary) or into a vector where the coefficient for each token could be binary, based on word count, based on tf-idf...\n\nBy default, all punctuation is removed, turning the texts into space-separated sequences of words (words maybe include the ' character). These sequences are then split into lists of tokens. They will then be indexed or vectorized.m\n\n## Using Pad Sequences\nThis function transforms a list (of length num_samples) of sequences (lists of integers) into a 2D Numpy array of shape (num_samples, num_timesteps). num_timesteps is either the maxlen argument if provided, or the length of the longest sequence in the list.\n\n","metadata":{"execution":{"iopub.status.busy":"2022-10-05T18:21:42.781134Z","iopub.execute_input":"2022-10-05T18:21:42.782029Z","iopub.status.idle":"2022-10-05T18:21:42.817555Z","shell.execute_reply.started":"2022-10-05T18:21:42.781895Z","shell.execute_reply":"2022-10-05T18:21:42.815961Z"}}},{"cell_type":"code","source":"\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","metadata":{"execution":{"iopub.status.busy":"2022-10-04T23:34:50.361302Z","iopub.execute_input":"2022-10-04T23:34:50.362513Z","iopub.status.idle":"2022-10-04T23:34:50.368283Z","shell.execute_reply.started":"2022-10-04T23:34:50.362471Z","shell.execute_reply":"2022-10-04T23:34:50.367204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer=Tokenizer(oov_token=\"<OOV>\")\ntokenizer.fit_on_texts(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-10-04T23:36:05.740275Z","iopub.execute_input":"2022-10-04T23:36:05.740728Z","iopub.status.idle":"2022-10-04T23:36:05.857285Z","shell.execute_reply.started":"2022-10-04T23:36:05.740691Z","shell.execute_reply":"2022-10-04T23:36:05.856163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tokenizer.index_word[1])\nprint(tokenizer.index_word[2])","metadata":{"execution":{"iopub.status.busy":"2022-10-04T23:45:55.276218Z","iopub.execute_input":"2022-10-04T23:45:55.276640Z","iopub.status.idle":"2022-10-04T23:45:55.282584Z","shell.execute_reply.started":"2022-10-04T23:45:55.276604Z","shell.execute_reply":"2022-10-04T23:45:55.281240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_seq=tokenizer.texts_to_sequences(X_train)\nX_test_seq=tokenizer.texts_to_sequences(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-10-04T23:37:24.261086Z","iopub.execute_input":"2022-10-04T23:37:24.261426Z","iopub.status.idle":"2022-10-04T23:37:24.370750Z","shell.execute_reply.started":"2022-10-04T23:37:24.261400Z","shell.execute_reply":"2022-10-04T23:37:24.369894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_seq[0]","metadata":{"execution":{"iopub.status.busy":"2022-10-04T23:37:37.725114Z","iopub.execute_input":"2022-10-04T23:37:37.726253Z","iopub.status.idle":"2022-10-04T23:37:37.735607Z","shell.execute_reply.started":"2022-10-04T23:37:37.726202Z","shell.execute_reply":"2022-10-04T23:37:37.734792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_seq_padded = pad_sequences(X_train_seq,maxlen=50, padding='post')\nX_test_seq_padded = pad_sequences(X_test_seq,maxlen=50, padding='post')","metadata":{"execution":{"iopub.status.busy":"2022-10-04T23:39:51.200914Z","iopub.execute_input":"2022-10-04T23:39:51.201338Z","iopub.status.idle":"2022-10-04T23:39:51.224739Z","shell.execute_reply.started":"2022-10-04T23:39:51.201298Z","shell.execute_reply":"2022-10-04T23:39:51.223943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_seq_padded[0]","metadata":{"execution":{"iopub.status.busy":"2022-10-04T23:40:03.502776Z","iopub.execute_input":"2022-10-04T23:40:03.503182Z","iopub.status.idle":"2022-10-04T23:40:03.512577Z","shell.execute_reply.started":"2022-10-04T23:40:03.503148Z","shell.execute_reply":"2022-10-04T23:40:03.511314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Building the model\nmodel = keras.Sequential()\n# Add an Embedding layer expecting input vocab of size 1000, and\n# output embedding dimension of size 32.\nmodel.add(layers.Embedding(input_dim=len(tokenizer.index_word)+1, output_dim=32)) #ypu can test output_dim\n\n# Add a LSTM layer with 128 internal units.\nmodel.add(layers.LSTM(32, dropout=0, recurrent_dropout=0)) #output of previous layer i.e 32\n\n# Add a Dense layer with 10 units.\nmodel.add(layers.Dense(32, activation='relu'))\n#final layer which will tell whether it's a spam or ham\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-10-04T23:49:37.271874Z","iopub.execute_input":"2022-10-04T23:49:37.272307Z","iopub.status.idle":"2022-10-04T23:49:37.644026Z","shell.execute_reply.started":"2022-10-04T23:49:37.272275Z","shell.execute_reply":"2022-10-04T23:49:37.642813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow.keras.backend as K\ndef recall_m(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives / (possible_positives + K.epsilon())\n        return recall\n\ndef precision_m(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n\n#compile the model\nmodel.compile(\n    loss='binary_crossentropy',\n    optimizer=\"adam\",\n    metrics=['accuracy',recall_m,precision_m]\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-10-04T23:59:02.195076Z","iopub.execute_input":"2022-10-04T23:59:02.195473Z","iopub.status.idle":"2022-10-04T23:59:02.209633Z","shell.execute_reply.started":"2022-10-04T23:59:02.195443Z","shell.execute_reply":"2022-10-04T23:59:02.208295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model.fit(\n    X_train_seq_padded, y_train, validation_data=(X_test_seq_padded, y_test), batch_size=32, epochs=10\n)","metadata":{"execution":{"iopub.status.busy":"2022-10-04T23:59:53.456960Z","iopub.execute_input":"2022-10-04T23:59:53.457359Z","iopub.status.idle":"2022-10-05T00:00:57.837047Z","shell.execute_reply.started":"2022-10-04T23:59:53.457329Z","shell.execute_reply":"2022-10-05T00:00:57.835538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the evaluation metrics by each epoch for the model to see if we are over or underfitting\nimport matplotlib.pyplot as plt\n\nfor i in ['accuracy', 'precision_m', 'recall_m']:\n    acc = history.history[i]\n    val_acc = history.history['val_{}'.format(i)]\n    epochs = range(1, len(acc) + 1)\n\n    plt.figure()\n    plt.plot(epochs, acc, label='Training Accuracy')\n    plt.plot(epochs, val_acc, label='Validation Accuracy')\n    plt.title('Results for {}'.format(i))\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-10-05T00:00:57.839250Z","iopub.execute_input":"2022-10-05T00:00:57.839689Z","iopub.status.idle":"2022-10-05T00:00:58.377962Z","shell.execute_reply.started":"2022-10-05T00:00:57.839656Z","shell.execute_reply":"2022-10-05T00:00:58.376779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}